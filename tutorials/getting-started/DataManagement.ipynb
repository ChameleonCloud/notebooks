{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data management in the cloud\n",
    "\n",
    "- **Estimated time**: 15 minutes\n",
    "- **Requirements**:\n",
    "  - An active node on Chameleon with a Floating IP, provisioned with a Key Pair on this Jupyter instance (so you can SSH)\n",
    "\n",
    "In this tutorial we'll go over the various ways you can deal with everything concering storage for your experiment: software, configuration, input data sets and outputs or experiment results. You'll learn what Chameleon can offer for your various experimental needs, but also will learn strategies for how to think about storage on the cloud.\n",
    "\n",
    "## Background: Data strategies on the cloud\n",
    "\n",
    "Unlike a server you may have plugged in to a wall that your lab group uses, or a laptop, cloud environments should ideally be considered ephemeral. While this sounds like a constraint at first, it actually unlocks a lot of interesting possibilities. Ephemeral environments require reproducibility, because you will probably need to re-create your experiment setup several times. Therefore, investing some time in learning about how to properly store all the data and configuration for your experiment can be helpful. There are a few common storage patterns on the cloud:\n",
    "\n",
    "- **Bootable disk images**: the bread and butter of the cloud. You need something to boot, after all! Bootable images work best when they contain the minimum amount of configuration to start your experiment. You can and should customize your boot image to contain dependencies required for your experiment. It can be helpful to work off of a simple base image and install additional software, and then save your changes as a snapshot, rather than attempt to build a disk image from scratch.\n",
    "  - AWS equivalent: [AMIs](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html)\n",
    "  - Chameleon equivalent: [Images (Glance)](https://chameleoncloud.readthedocs.io/en/latest/technical/images.html)\n",
    "- **Ephemeral storage**: any data written to your instance's primary block device is usually not persisted, unless you opt to snapshot your disk image or otherwise base your disk image _on top of_ a mountable block device (AWS EBS volumes can work like this, for example.) This is good and bad; you can get in to a bad state and easily revert to a clean image, but can also lose important data if it is not persisted somewhere.\n",
    "- **Mountable block devices**: mountable volumes are nice for persistent storage not necessarily related to the operations of your image. For example, your bootable image might contain the MySQL binaries, but you may store the database itself on a mountable block device, so that when your instance is destroyed, you can first detach the block device and later re-attach it to a new instance, thus preserving all of your data in practice.\n",
    "  - AWS equivalent: [EBS](https://aws.amazon.com/ebs/), [EFS](https://aws.amazon.com/efs/)\n",
    "  - Chameleon equivalent: _Not yet supported_\n",
    "- **Object storage**: unlike a block device, an object storage system stores files as binary blobs; it has no concept of a file as consisting of multiple chunks of data. This has some interesting implications. First of all, object storage systems tend to scale very well on the cloud, because you can replicate and store binary blobs with great ease. Object storage also supports arbitrary metadata attached to an object, usually including at least a checksum for integrity verification, but also security levels, ACLs, and further descriptions of the data. Object storage is a great solution for data that you need to read or bootstrap into your experimental environment, and also provides an easy mechanism for sharing data sets with others. However, it cannot be effectively used like a \"real\" filesystem, as you cannot incrementally or partially edit/update a file; you must make a new copy of the object and write the contents over top of the old copy. This can have performance implications in write-heavy workloads.\n",
    "  - AWS equilvalent: [S3](https://aws.amazon.com/s3/)\n",
    "  - Chameleon equivalent: [Object Store (Swift)](https://chameleoncloud.readthedocs.io/en/latest/technical/swift.html)\n",
    "  \n",
    "We'll now go over what options are available to you in Chameleon, so you are better-equipped to address your storage needs.\n",
    "\n",
    "## Tutorial\n",
    "\n",
    "1. [Creating your own disk image](#Creating-your-own-disk-image)\n",
    "1. [Using the mounted Object Store](#Using-the-mounted-Object-Store)\n",
    "1. [Using the Object Store directly](#Using-the-Object-Store-directly)\n",
    "\n",
    "### Variables you'll see/use in this Notebook\n",
    "\n",
    "  - `FLOATING_IP`: a Floating IP attached to your running instance\n",
    "  - `OS_REGION_NAME`: the Chameleon site name, e.g. CHI@TACC or CHI@UC\n",
    "  - `OS_PROJECT_NAME`: the Chameleon project to authenticate under. You might need to set this if no project was automatically chosen for you (which can happen if you are on multiple projects!)\n",
    "  \n",
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting up to 300 seconds for SSH on 192.5.87.33...\n",
      "SSH is running!\n"
     ]
    }
   ],
   "source": [
    "FLOATING_IP=\"192.5.87.33\" # Required\n",
    "OS_REGION_NAME=\"${OS_REGION_NAME:-CHI@UC}\"\n",
    "if [[ -z \"${OS_PROJECT_NAME:+x}\" ]]; then\n",
    "  OS_PROJECT_NAME=\"CH-XXXXXX\" # For example.\n",
    "fi\n",
    "\n",
    "# Create shortcut for SSH\n",
    "do_ssh() {\n",
    "  ssh cc@$FLOATING_IP \"$@\"\n",
    "}\n",
    "\n",
    "wait_ssh \"$FLOATING_IP\"\n",
    "# Kludgy way to ensure your server has latest snapshot utility (force past update prompt)\n",
    "do_ssh timeout 10 \"yes | sudo cc-snapshot\" >/dev/null 2>/dev/null || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your own disk image\n",
    "\n",
    "When you are logged in to one of your bare metal nodes, and you're using a disk image derived from one of Chameleon's official images ([CentOS7](https://www.chameleoncloud.org/appliances/1/) or [Ubuntu16.04](https://www.chameleoncloud.org/appliances/19/), for example), you will have access to a tool called `cc-snapshot`. This tool allows you to create a new bootable disk image from your current filesystem contents. It was created to get around a limitation with the [OpenStack Ironic](https://docs.openstack.org/ironic) bare metal provisioning system, which does not support snapshotting similar to how you would for a VM.\n",
    "\n",
    "You can interactively use the tool by just running `cc-snapshot` (requires sudo). It will prompt you for your Chameleon username and password; this is necessary to save the resulting disk image back up to Chameleon. It may also ask you if you'd like to update the script. This is recommended, as bugs are fixed from time to time.\n",
    "\n",
    "We will create a snapshot of your instance now. We'll craft a special invocation of `cc-snapshot` so we can run it over SSH. You can also try connecting to your node via SSH in a Jupyter Terminal and running it interactively if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will snapshot the instance using the following name: 'jason_a-tutorial-snapshot-May30'\n",
      "BDB2053 Freeing read locks for locker 0x54: 23942/140308114094208\n",
      "BDB2053 Freeing read locks for locker 0x56: 23942/140308114094208\n",
      "BDB2053 Freeing read locks for locker 0x57: 23942/140308114094208\n",
      "BDB2053 Freeing read locks for locker 0x58: 23942/140308114094208\n",
      "Package 1:libguestfs-xfs-1.38.2-12.el7_6.2.x86_64 already installed and latest version\n",
      "Nothing to do\n",
      "No packages marked for update\n",
      "tar: Removing leading `/' from member names\n",
      "tar: Removing leading `/' from hard link targets\n",
      "[   0.0] Examining the guest ...\n",
      "[   2.0] Setting a random seed\n",
      "[   2.0] Running: grub2-install /dev/sda && grub2-mkconfig -o /boot/grub2/grub.cfg\n",
      "[   9.5] Finishing off\n",
      "[   0.0] Examining the guest ...\n",
      "[   2.2] Performing \"abrt-data\" ...\n",
      "[   2.2] Performing \"backup-files\" ...\n",
      "[   2.9] Performing \"bash-history\" ...\n",
      "[   2.9] Performing \"blkid-tab\" ...\n",
      "[   2.9] Performing \"crash-data\" ...\n",
      "[   2.9] Performing \"cron-spool\" ...\n",
      "[   2.9] Performing \"dhcp-client-state\" ...\n",
      "[   2.9] Performing \"dhcp-server-state\" ...\n",
      "[   2.9] Performing \"dovecot-data\" ...\n",
      "[   2.9] Performing \"logfiles\" ...\n",
      "[   3.0] Performing \"machine-id\" ...\n",
      "[   3.0] Performing \"mail-spool\" ...\n",
      "[   3.0] Performing \"net-hostname\" ...\n",
      "[   3.1] Performing \"net-hwaddr\" ...\n",
      "[   3.2] Performing \"pacct-log\" ...\n",
      "[   3.2] Performing \"package-manager-cache\" ...\n",
      "[   3.3] Performing \"pam-data\" ...\n",
      "[   3.3] Performing \"passwd-backups\" ...\n",
      "[   3.3] Performing \"puppet-data-log\" ...\n",
      "[   3.3] Performing \"rh-subscription-manager\" ...\n",
      "[   3.3] Performing \"rhn-systemid\" ...\n",
      "[   3.3] Performing \"rpm-db\" ...\n",
      "[   3.3] Performing \"samba-db-log\" ...\n",
      "[   3.3] Performing \"script\" ...\n",
      "[   3.3] Performing \"smolt-uuid\" ...\n",
      "[   3.3] Performing \"ssh-hostkeys\" ...\n",
      "[   3.3] Performing \"ssh-userdir\" ...\n",
      "[   3.3] Performing \"sssd-db-log\" ...\n",
      "[   3.3] Performing \"tmp-files\" ...\n",
      "[   3.3] Performing \"udev-persistent-net\" ...\n",
      "[   3.3] Performing \"utmp\" ...\n",
      "[   3.3] Performing \"yum-uuid\" ...\n",
      "[   3.3] Performing \"customize\" ...\n",
      "[   3.3] Setting a random seed\n",
      "[   3.3] Setting the machine ID in /etc/machine-id\n",
      "[   3.6] Performing \"lvm-uuids\" ...\n",
      "+------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Field            | Value                                                                                                                                                                                      |\n",
      "+------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| checksum         | bc5e55cfc1bfd8ca4567d8684247ed7b                                                                                                                                                           |\n",
      "| container_format | bare                                                                                                                                                                                       |\n",
      "| created_at       | 2019-05-30T01:50:45Z                                                                                                                                                                       |\n",
      "| disk_format      | qcow2                                                                                                                                                                                      |\n",
      "| file             | /v2/images/bc8599df-c260-4c38-b18b-d4c433a22099/file                                                                                                                                       |\n",
      "| id               | bc8599df-c260-4c38-b18b-d4c433a22099                                                                                                                                                       |\n",
      "| min_disk         | 0                                                                                                                                                                                          |\n",
      "| min_ram          | 0                                                                                                                                                                                          |\n",
      "| name             | jason_a-tutorial-snapshot-May30                                                                                                                                                            |\n",
      "| owner            | 975c0a94b784483a885f4503f70af655                                                                                                                                                           |\n",
      "| properties       | os_hash_algo='sha512', os_hash_value='99082c12c1aa61f3af3324f4a4bd210b3cbc48e57404e774b515faa2fc01bfb7d7348c5cfe8aab40cc81b4392056c913e2f1a321e602bdc17a838cace12a13fd', os_hidden='False' |\n",
      "| protected        | False                                                                                                                                                                                      |\n",
      "| schema           | /v2/schemas/image                                                                                                                                                                          |\n",
      "| size             | 889971200                                                                                                                                                                                  |\n",
      "| status           | active                                                                                                                                                                                     |\n",
      "| tags             |                                                                                                                                                                                            |\n",
      "| updated_at       | 2019-05-30T01:50:53Z                                                                                                                                                                       |\n",
      "| virtual_size     | None                                                                                                                                                                                       |\n",
      "| visibility       | shared                                                                                                                                                                                     |\n",
      "+------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "snapshot_name=\"$USER-tutorial-snapshot-$(date +%b%d)\"\n",
    "\n",
    "# We do a little trick to pass our authentication token to our remote\n",
    "# instance here by setting OS_TOKEN and OS_AUTH_TYPE.\n",
    "# We also invoke with some flags, -f and -y, which help us skip any\n",
    "# prompts (necessary because Jupyter Bash cannot wait for input)\n",
    "do_ssh sudo env OS_TOKEN=$OS_TOKEN OS_AUTH_TYPE=token \\\n",
    "  cc-snapshot -fy \"$snapshot_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your image should now be visible in the [Images panel](https://chi.uc.chameleoncloud.org/project/images) in the Chameleon GUI. You may have to filter for your username to find it if there are a lot of images available to your project. You can now use this image when launching a new bare metal instance!\n",
    "\n",
    "Creating a disk snapshot is a great way to save the state of a node so you can resume your work later, after your lease ends for example. However, it may not be a good idea to store a bunch of data in a disk image. Disk images are best when they are lean and easy to launch/start. Large data sets, or experimental data that you'd like to store in an easily sharable way, are better suited for the Object Store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the mounted Object Store\n",
    "\n",
    "The Chameleon [Object Store](https://chameleoncloud.readthedocs.io/en/latest/technical/swift.html) contains several petabytes of storage for your use. Chameleon exposes it to you in a number of ways, but the most immediately obvious may be in a special mounted directory you may have already noticed inside your instance. The `my_mounting_point` folder in your default home directory is a [cloudfuse](https://github.com/redbo/cloudfuse) mount of the Chameleon Object Store, where your various data objects are presented as files in a navigable tree. You can interact with it much like you would a normal file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects found in 'jason_a-tutorial-container':\n",
      "+---------------+\n",
      "| Name          |\n",
      "+---------------+\n",
      "| TestFile.txt  |\n",
      "| TestFile2.txt |\n",
      "+---------------+\n",
      "Objects found in 'jason_a-tutorial-container' after deletion:\n",
      "+--------------+\n",
      "| Name         |\n",
      "+--------------+\n",
      "| TestFile.txt |\n",
      "+--------------+\n"
     ]
    }
   ],
   "source": [
    "container_name=$USER-tutorial-container\n",
    "\n",
    "# Writing a folder writes a new container (namespace) to the\n",
    "# Object Store owned by your current Project.\n",
    "do_ssh mkdir -p my_mounting_point/$container_name\n",
    "\n",
    "# Writing files creates new objects\n",
    "do_ssh bash -c \"echo Test >my_mounting_point/$container_name/TestFile.txt\"\n",
    "do_ssh bash -c \"echo Test >my_mounting_point/$container_name/TestFile2.txt\"\n",
    "\n",
    "echo \"Objects found in '$container_name':\"\n",
    "openstack object list \"$container_name\"\n",
    "\n",
    "do_ssh rm my_mounting_point/$container_name/TestFile2.txt\n",
    "\n",
    "echo \"Objects found in '$container_name' after deletion:\"\n",
    "openstack object list \"$container_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it looks like a normal filesystem, under the hood you are making requests to the Object Store. Because the underlying representation is an object, rather than a file, you could suffer severe performance penalties depending on your usage. You should consult our documentation to learn more about this. In general, it is a nice way to get acquainted with the Object Store, and could be fine for your use-cases, especially if your experiment is read-intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Object Store directly\n",
    "\n",
    "The Object Store is also exposed via its OpenStack API, which means you can, once again, use the `openstack` CLI tool to access it. The Object Store functions are under the `openstack object` top-level command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading this Notebook!\n",
      "+----------------+----------------------------------+\n",
      "| Field          | Value                            |\n",
      "+----------------+----------------------------------+\n",
      "| account        | v1                               |\n",
      "| container      | jason_a-tutorial-container       |\n",
      "| content-length | 18560                            |\n",
      "| content-type   | binary/octet-stream              |\n",
      "| etag           | 8332695bfd8af037c6f10ad9f6844b11 |\n",
      "| last-modified  | Thu, 30 May 2019 02:06:54 GMT    |\n",
      "| object         | DataManagement.ipynb             |\n",
      "+----------------+----------------------------------+\n"
     ]
    }
   ],
   "source": [
    "echo \"Uploading this Notebook!\"\n",
    "\n",
    "openstack object create $container_name DataManagement.ipynb >/dev/null \\\n",
    "  && openstack object show $container_name DataManagement.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are dealing with particularly large files, you should look into using the `swift` CLI tool instead, which is a more specialized tool for just the underlying OpenStack service that powers the Object Store, named [Swift](https://docs.openstack.org/swift). The `swift` tool in particular supports multi-threading and also transparently breaking large files (> 5GB) into chunks for easier (and parallel) transmission. It can also be used to customize ACLs on your objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: swift upload [--changed] [--skip-identical] [--segment-size <size>]\n",
      "                    [--segment-container <container>] [--leave-segments]\n",
      "                    [--object-threads <thread>] [--segment-threads <threads>]\n",
      "                    [--meta <name:value>] [--header <header>] [--use-slo]\n",
      "                    [--ignore-checksum] [--object-name <object-name>]\n",
      "                    <container> <file_or_directory> [<file_or_directory>] [...]\n",
      "\n",
      "Uploads specified files and directories to the given container.\n",
      "\n",
      "Positional arguments:\n",
      "  <container>           Name of container to upload to.\n",
      "  <file_or_directory>   Name of file or directory to upload. Specify multiple\n",
      "                        times for multiple uploads. If \"-\" is specified, reads\n",
      "                        content from standard input (--object-name is required\n",
      "                        in this case).\n",
      "\n",
      "Optional arguments:\n",
      "  -c, --changed         Only upload files that have changed since the last\n",
      "                        upload.\n",
      "  --skip-identical      Skip uploading files that are identical on both sides.\n",
      "  -S, --segment-size <size>\n",
      "                        Upload files in segments no larger than <size> (in\n",
      "                        Bytes) and then create a \"manifest\" file that will\n",
      "                        download all the segments as if it were the original\n",
      "                        file.\n",
      "  --segment-container <container>\n",
      "                        Upload the segments into the specified container. If\n",
      "                        not specified, the segments will be uploaded to a\n",
      "                        <container>_segments container to not pollute the\n",
      "                        main <container> listings.\n",
      "  --leave-segments      Indicates that you want the older segments of manifest\n",
      "                        objects left alone (in the case of overwrites).\n",
      "  --object-threads <threads>\n",
      "                        Number of threads to use for uploading full objects.\n",
      "                        Default is 10.\n",
      "  --segment-threads <threads>\n",
      "                        Number of threads to use for uploading object segments.\n",
      "                        Default is 10.\n",
      "  -m, --meta <name:value>\n",
      "                        Sets a meta data item. This option may be repeated.\n",
      "                        Example: -m Color:Blue -m Size:Large\n",
      "  -H, --header <header:value>\n",
      "                        Adds a customized request header. This option may be\n",
      "                        repeated. Example: -H \"content-type:text/plain\"\n",
      "                         -H \"Content-Length: 4000\".\n",
      "  --use-slo             When used in conjunction with --segment-size it will\n",
      "                        create a Static Large Object instead of the default\n",
      "                        Dynamic Large Object.\n",
      "  --object-name <object-name>\n",
      "                        Upload file and name object to <object-name> or upload\n",
      "                        dir and use <object-name> as object prefix instead of\n",
      "                        folder name.\n",
      "  --ignore-checksum     Turn off checksum validation for uploads.\n"
     ]
    }
   ],
   "source": [
    "# Not actually giving a nice example because the raw Swift\n",
    "# client doesn't support token-authentication (requires you\n",
    "# to type in your username/password every time.)\n",
    "swift upload -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "You should now have a bootable image snapshot and be more familiar with the `cc-snapshot` tool. You should also understand what the `my_mounting_point` directory is, how it works, and what it is good for. Finally, you should have gained some familiarity with some more commands for the `openstack` CLI around managing data in the Chameleon Object Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
